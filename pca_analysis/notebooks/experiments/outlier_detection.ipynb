{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: outlier detection\n",
    "description: outlier detection through mahalanobis clustering\n",
    "project: eda\n",
    "status: open\n",
    "conclusion: \"\"\n",
    "cdt: 2024-08-15T00:00:00\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection\n",
    "\n",
    "1. get the data\n",
    "2. reshape the data\n",
    "3. PCA\n",
    "4. viz PCA, first 2.\n",
    "5. Mahalanobis clustering analysis / outlier detection.\n",
    "\n",
    "Troubleshoot throughout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as db\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"\n",
    "    Get the data out of the db.\n",
    "    \"\"\"\n",
    "\n",
    "    db_path = \"/Users/jonathan/mres_thesis/wine_analysis_hplc_uv/wines.db\"\n",
    "\n",
    "    with db.connect(db_path) as con:\n",
    "        data_query = \"\"\"--sql\n",
    "            CREATE OR REPLACE TEMP TABLE raw_shiraz AS (\n",
    "            SELECT\n",
    "                *\n",
    "            FROM\n",
    "                pbl.sample_metadata\n",
    "            WHERE\n",
    "                detection='raw'\n",
    "            AND\n",
    "              varietal='shiraz'\n",
    "            ORDER BY\n",
    "                sample_num\n",
    "            );\n",
    "            SELECT\n",
    "                *\n",
    "            FROM\n",
    "                pbl.chromatogram_spectra_long as cs\n",
    "            JOIN\n",
    "            raw_shiraz\n",
    "            USING\n",
    "                (id)\n",
    "            WHERE\n",
    "                cs.mins < 30\n",
    "            ORDER BY\n",
    "                sample_num, idx\n",
    "                ;\n",
    "            \"\"\"\n",
    "\n",
    "        get_sm_query = \"\"\"--sql\n",
    "        select * from raw_shiraz;\n",
    "        \"\"\"\n",
    "\n",
    "        data = con.sql(data_query).pl()\n",
    "        sm = con.sql(get_sm_query).pl()\n",
    "\n",
    "        return data, sm\n",
    "\n",
    "\n",
    "long_data, sm = get_data()\n",
    "display(Markdown(\"## Sample Metadata\"), sm)\n",
    "display(Markdown(\"## Sample Metadata\"), long_data.head(), long_data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that all samples are retrieved after the join\n",
    "\n",
    "assert sm.select(\"sample_num\").n_unique() == long_data.select(\"sample_num\").n_unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the id column \"sample_num\" is a unique identifier\n",
    "\n",
    "sample_num_grps = long_data.group_by(\"sample_num\")\n",
    "with pl.Config() as cfg:\n",
    "    cfg.set_tbl_rows(11)\n",
    "    display(sample_num_grps.len())\n",
    "\n",
    "    # simple test, if any are 50% greater than the average, then there is a doubling\n",
    "\n",
    "    outlier_lengths = sample_num_grps.len().filter(\n",
    "        pl.col(\"len\") > pl.col(\"len\").mean().mul(1.5)\n",
    "    )\n",
    "    assert (\n",
    "        outlier_lengths.is_empty()\n",
    "    ), f\"outlier sample signal length detected: {outlier_lengths}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data.\n",
    "display(long_data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the data\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "rp = sns.relplot(\n",
    "    data=long_data.filter(pl.col(\"wavelength\").eq(256)),\n",
    "    x=\"mins\",\n",
    "    y=\"absorbance\",\n",
    "    col=\"sample_num\",\n",
    "    col_wrap=6,\n",
    "    kind=\"line\",\n",
    "    height=3,\n",
    ")\n",
    "title = \"HPLC-DAD Shiraz @ 256nm\"\n",
    "rp.figure.subplots_adjust(top=0.8)\n",
    "plt.suptitle(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, sample 75 is obviously an outlier and easily considered a failed run. We will leave it in to see whether the outlier detection behaves as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahalanibos Covariance Matrix\n",
    "\n",
    "See https://scikit-learn.org/stable/auto_examples/covariance/plot_mahalanobis_distances.html for an exmaple of how to do it in scikit learn.\n",
    "\n",
    "From what ive gathered skimmiing the net, the general approach is to unfold each 3 way data such that each vector is a sample and each component is absorbance at a given wavelength/time. As per [@brereton_appliedchemometricsscientists_2007, p. 215, sec. \"6.8.1 Unfolding\"] This has the downside of both massively increasing the redundancy of the data and disconnecting the time and wavelength information connection.\n",
    "\n",
    "That being said, I can't find any good examples of tensor covariance calculations.\n",
    "That also being said, numpy appears to support multidimensional data covariance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_data = (\n",
    "    long_data.select(\"sample_num\", \"mins\", \"absorbance\", \"wavelength\")\n",
    "    .sort([\"sample_num\", \"mins\", \"wavelength\"])\n",
    "    .pivot(\n",
    "        on=\"wavelength\",\n",
    "        index=[\"sample_num\", \"mins\"],\n",
    "        values=\"absorbance\",\n",
    "        maintain_order=True,\n",
    "    )\n",
    "    .drop(\"mins\")\n",
    ")\n",
    "wide_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAFAC2\n",
    "\n",
    "According to @bro_parafac2partii_1999, PARAFAC2 can decompose multiway data into three matrices containing each compounds elution profile, spectral profile and a concentration value. This should be the area of focus. The research is over 25 years old, it should be mature enough to get results. Validation can simply be done by summing the elution profiles at a given wavelength (or all wavelengths) and observing the difference from the original.\n",
    "\n",
    "The pipeline should be done on a toy dataset - one sample, then expanded to my data. First difficulty will be finding a toy dataset. Actually can probs just follow the tensorly tutorial. The tutorial will done[here]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folding\n",
    "\n",
    "As usual, getting the data into the form expected is a difficult one to ascertain as different schools use different terms. Tensorly may be promising software which provides a lot of algorithms you want to use.\n",
    "\n",
    "From a quick look on the web it looks like tensorflow has the most convenient api for dataframe -> tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis\n",
    "\n",
    "According to @miller_statisticschemometricsanalytical_2018 we [p. 243, sec. \"cluster analysis\"] need to perform heirarchical cluster analysis, or K Means. Sci-kit provides all the required algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Means\n",
    "\n",
    "We'll do k-Means first as its conceptually more straight forward.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
