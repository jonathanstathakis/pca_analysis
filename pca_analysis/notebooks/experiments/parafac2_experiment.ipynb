{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "cdt: 2024-08-24T00:00:00\n",
    "title: First Look at PARAFAC2 on Core Dataset\n",
    "description: \"Can I run PARAFAC on my data. This experiment will merely prove that I can run the tensorly implementation of PARAFAC2 with my dataset. It will require the following: 1. my data is in the right format 2. the tensorly PARAFAC2 code, 3. interpretation of results. What are the results? visualisation of the decomposed modes and a fit, or reconstruction report.\"\n",
    "conclusion: \"\"\n",
    "status: open\n",
    "project: parafac2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorly Demonstration Code\n",
    "\n",
    "The following has been adapted from <https://tensorly.org/stable/auto_examples/decomposition/plot_parafac2.html>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorly as tl\n",
    "import duckdb as db\n",
    "import polars as pl\n",
    "from IPython.display import Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    Get the data out of the db.\n",
    "    \"\"\"\n",
    "\n",
    "    db_path = \"/Users/jonathan/mres_thesis/wine_analysis_hplc_uv/wines.db\"\n",
    "\n",
    "    with db.connect(db_path) as con:\n",
    "        data_query = \"\"\"--sql\n",
    "            CREATE OR REPLACE TEMP TABLE raw_shiraz AS (\n",
    "            SELECT\n",
    "                *\n",
    "            FROM\n",
    "                pbl.sample_metadata\n",
    "            WHERE\n",
    "                detection='raw'\n",
    "            AND\n",
    "              varietal='shiraz'\n",
    "            ORDER BY\n",
    "                sample_num\n",
    "            );\n",
    "            SELECT\n",
    "                *\n",
    "            FROM\n",
    "                pbl.chromatogram_spectra_long as cs\n",
    "            JOIN\n",
    "            raw_shiraz\n",
    "            USING\n",
    "                (id)\n",
    "            WHERE\n",
    "                cs.mins < 30\n",
    "            ORDER BY\n",
    "                sample_num, cs.wavelength, idx\n",
    "                ;\n",
    "            \"\"\"\n",
    "\n",
    "        get_sm_query = \"\"\"--sql\n",
    "        select * from raw_shiraz;\n",
    "        \"\"\"\n",
    "\n",
    "        data = con.sql(data_query).pl()\n",
    "        sm = con.sql(get_sm_query).pl()\n",
    "\n",
    "        return data, sm\n",
    "\n",
    "\n",
    "long_data, sm = get_data()\n",
    "display(Markdown(\"## Sample Metadata\"), sm)\n",
    "display(Markdown(\"## Sample Metadata\"), long_data.head(), long_data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicate samples\n",
    "\n",
    "long_data.filter(pl.col(\"wavelength\").eq(256)).group_by(\"sample_num\").len().sort(\n",
    "    \"sample_num\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data.group_by(\"sample_num\").agg(\n",
    "    pl.col(\"wavelength\").min().alias(\"wavelength_min\"),\n",
    "    pl.col(\"wavelength\").max().alias(\"wavelength_max\"),\n",
    ").describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time ranges.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data.group_by(\"sample_num\").agg(\n",
    "    pl.col(\"mins\").min().alias(\"min\"), pl.col(\"mins\").max().alias(\"max\")\n",
    ").describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varies a bit.. cut it off at 25 mins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold to Tensor\n",
    "\n",
    "Need to fold the data across the sample and wavelength modes to form a 3 mode tensor. See <https://tensorly.org/stable/user_guide/tensor_basics.html#folding>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = long_data.filter(pl.col(\"mins\").le(25)).select(\n",
    "    \"sample_num\", \"mins\", \"absorbance\", \"wavelength\"\n",
    ")\n",
    "long_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank sample_num to have as continuous numerical\n",
    "\n",
    "long_df = long_df.with_columns(\n",
    "    pl.col(\"sample_num\").rank(\"dense\").alias(\"sample_num_rank\")\n",
    ")\n",
    "long_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.select(\"sample_num_rank\").n_unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are all wavelength ranges the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.select(\"wavelength\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    df\n",
    "    for df in long_df.select(\"sample_num_rank\", \"mins\", \"absorbance\", \"wavelength\")\n",
    "    .pivot(on=\"wavelength\", index=[\"sample_num_rank\", \"mins\"], values=\"absorbance\")\n",
    "    .partition_by(\"sample_num_rank\")\n",
    "]\n",
    "\n",
    "print([df.shape for df in dfs])\n",
    "I = 1\n",
    "J = 3750\n",
    "K = long_df.select(\"wavelength\").n_unique() + 2\n",
    "\n",
    "df_1_reshaped = dfs[1].to_numpy().reshape(1, J, K)\n",
    "\n",
    "print(\"reshaped frame shape:\", df_1_reshaped.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup for wavelength to numpy indice mapping\n",
    "\n",
    "wavelength_ranking = long_df.select(pl.col(\"wavelength\").unique()).with_columns(\n",
    "    pl.col(\"wavelength\").rank(\"dense\").sub(1).alias(\"rank\")\n",
    ")\n",
    "wavelength_ranking.filter(pl.col(\"wavelength\").eq(256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_ranking[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arrays = [df.to_numpy() for df in dfs]\n",
    "tensor = np.stack(np_arrays)\n",
    "print(tensor.shape)\n",
    "plt.plot(tensor[1, :, 33])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the data\n",
    "\n",
    "Lets give the data a whirl, now that its tensor-i-fied. I suspect some white wines would be an easier prospect considering the absence of a shifting baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_err = np.inf\n",
    "decomposition = None\n",
    "\n",
    "true_rank = 30\n",
    "\n",
    "for run in range(1):\n",
    "    print(f\"Training model {run}...\")\n",
    "    trial_decomposition, trial_errs = parafac2(\n",
    "        tensor,\n",
    "        true_rank,\n",
    "        return_errors=True,\n",
    "        tol=1e-8,\n",
    "        n_iter_max=500,\n",
    "        random_state=run,\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(f\"Number of iterations: {len(trial_errs)}\")\n",
    "    print(f\"Final error: {trial_errs[-1]}\")\n",
    "    if best_err > trial_errs[-1]:\n",
    "        best_err = trial_errs[-1]\n",
    "        err = trial_errs\n",
    "        decomposition = trial_decomposition\n",
    "    print(\"-------------------------------\")\n",
    "print(f\"Best model error: {best_err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_B[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[[1]].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_parafac_2(tensor, true_rank, **kwargs):\n",
    "    best_err = np.inf\n",
    "    decomposition = None\n",
    "\n",
    "    true_rank = 30\n",
    "\n",
    "    for run in range(1):\n",
    "        print(f\"Training model {run}...\")\n",
    "        trial_decomposition, trial_errs = parafac2(\n",
    "            tensor,\n",
    "            true_rank,\n",
    "            return_errors=True,\n",
    "            tol=1e-8,\n",
    "            n_iter_max=500,\n",
    "            random_state=run,\n",
    "            verbose=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "        print(f\"Number of iterations: {len(trial_errs)}\")\n",
    "        print(f\"Final error: {trial_errs[-1]}\")\n",
    "        if best_err > trial_errs[-1]:\n",
    "            best_err = trial_errs[-1]\n",
    "            decomposition = trial_decomposition\n",
    "        print(\"-------------------------------\")\n",
    "    print(f\"Best model error: {best_err}\")\n",
    "\n",
    "    est_tensor = tl.parafac2_tensor.parafac2_to_tensor(decomposition)\n",
    "    est_weights, (est_A, est_B, est_C) = tl.parafac2_tensor.apply_parafac2_projections(\n",
    "        decomposition\n",
    "    )\n",
    "\n",
    "    return decomposition, est_tensor, est_weights, est_A, est_B, est_C\n",
    "\n",
    "\n",
    "decomposition, est_tensor, est_weights, est_A, est_B, est_C = fit_parafac_2(\n",
    "    tensor=tensor[[1]], true_rank=30, nn_modes=\"all\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition.projections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 0\n",
    "\n",
    "print(est_B[sample].shape)\n",
    "x = np.sum(np.abs(est_B[sample]), axis=1)\n",
    "print(x.shape)\n",
    "plt.plot(x);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_diff = tensor[[1]] - est_tensor\n",
    "tensor_diff / tensor[[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = est_tensor[0, :, 33]\n",
    "print(x.shape)\n",
    "plt.plot(x)\n",
    "plt.plot(tensor[0, :, 33])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(est_B[0]);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
