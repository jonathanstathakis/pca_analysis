{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Partitioning by Peak Clusters\n",
    "cdt: 2024-12-17T11:51:48\n",
    "description: \"\"\n",
    "status: open\n",
    "conclusion: \"\"\n",
    "project: parafac2\n",
    "---\n",
    "TODO complete this module/notebook\n",
    "TODO fine tune clustering to goup the first 5 peaks together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One method of finding the points between clusters is to find local minima. The easiest way to do this is to invert the signal and run a peak finding routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Binning (Peak Picking)\n",
    "\n",
    "- @ianeselli_completeanalysispipeline_2024 used HAC. They preprocessed with smoothing and peak alignment and used unsupervised HAC with Euclidean distance metric and linkage and dendrogram height equal to the average width of the peaks.\n",
    "- @sinanian_multivariatecurveresolutionalternating_2016 binned to unit masses, but also discussed @bedia_compressionstrategieschemometric_2016 defining Regions of Interest (ROI), stating that while it is useful for greatly eliminating unnecessary data, it can miss low intensity peaks if the threshold is set too high.\n",
    "- @bedia_compressionstrategieschemometric_2016 describes a feature detection and data compression method based on the *centWave* algorithm.\n",
    "- @anthony_libraryintegratedsimplismaalsdeconvolution_2022 manually binned the peaks.\n",
    "- @anthony_libraryintegratedsimplismaalsdeconvolution_2022 state that simple models are better at peak picking than complicated, abstract ones. They describe current issues with peak picking as a significant bottleneck in metabolomic studies.\n",
    "- @haas_opensourcechromatographicdata_2023 released a Python GUI package for analysis of HPLC-DAD data including peak picking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "See [notes on clustering](../clustering.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO redefine the clustering pipeline seperate from the clustering module.\n",
    "\n",
    "from pca_analysis.preprocessing.pipeline import pipeline\n",
    "\n",
    "# ds_, box = clustering_by_maxima(\n",
    "#     ds=ds,\n",
    "#     signal_key=\"data_corr\",\n",
    "#     x_key=\"mins\",\n",
    "#     grouper=[\"id_rank\"],\n",
    "#     by_maxima=True,\n",
    "#     # savgol_kwargs=dict(\n",
    "#     #     polyorder=2,\n",
    "#     #     window_length=70,\n",
    "#     # ),\n",
    "#     display_facet_peaks_plot=True,\n",
    "#     display_cluster_table=True,\n",
    "#     facet_peak_plot_kwargs=dict(\n",
    "#         col_wrap=3,\n",
    "#     ),\n",
    "#     find_peaks_kws=dict(rel_height=0.5, prominence=2),\n",
    "#     clustering_kws=dict(\n",
    "#         n_clusters=None,\n",
    "#         distance_threshold=2,\n",
    "#         linkage=\"average\",\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# when not using `n_clusters`, lower `distance_threshold` increases number of\n",
    "# clusters.\n",
    "\n",
    "# when clustering by minima, if one signals minima coincides with another's maxima,\n",
    "# that peak will be cut. Thi     s is not desired.\n",
    "# box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "So now we will take a moment to study clustering of 1D arrays. [clustering](../clustering.ipynb). \n",
    "\n",
    "@ianeselli_completeanalysispipeline_2024 used heirarchical agglomerative clustering to cluster the peak maxima with a Euclidean distance metric and used average width linkage distance threshold (average linkage).\n",
    "\n",
    "\n",
    "Observations:\n",
    "- clustering on the whole dataset doesnt make any sense. Clustering on the whole signal would simply cluster accordnig to peak heights, i.e. along the y-axis, rather than the x. Thats why we detect peaks first. Either the minima or maxima. Now, Ianeselli chose to cluster the peak maxima rather than minima..\n",
    "- maximising the number of peaks maximises the extent of the signal captured into all clusters. This is actually beneficial for rough binning.\n",
    "- more often than not, the center of the inter-cluster regions approximate a local minima, meaning that splitting the interpeak areas between the two clusters is a good method of ensuring that all peak width is captured by its cluster region.\n",
    "- the problem of cluster labelling is akin to a [gap and island problem](https://mattboegner.com/improve-your-sql-skills-master-the-gaps-islands-problem/)\n",
    "\n",
    "TODO add a padding parameter\n",
    "TODO add a smoothing and sharpening routine.\n",
    "TODO achieve average peak density of 3 peaks per cluster. With sufficient smoothing/sharpening this should be possible.\n",
    "TODO add demonstrations for other cluster methods (integrate into function?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the results of which are quite acceptable. Without much fiddling, ranges are identified within which a reasonable amount of peaks fall (2 > x < 6). The only draw back is that some of the parameter values are currently hard coded data dependent values, meaning that a different baseline subtraction will require different values. A problem to be solved down track, but essentially means that every run will require a little manual tuning.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
