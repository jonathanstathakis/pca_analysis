{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Preprocessing\n",
    "cdt: 2024-12-03T12:15:03\n",
    "description: \"preprocessing. This can be the preprocessing demonstration and serve as an automated test until a more formal module can be established. It will need to individually demonstrate smoothing, sharpening and baseline subtraction.\"\n",
    "status: open\n",
    "conclusion: \"\"\n",
    "project: parafac2\n",
    "---\n",
    "\n",
    "TODO complete this notebook/module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3 --print\n",
    "\n",
    "import logging\n",
    "from pca_analysis import xr_signal\n",
    "\n",
    "from pca_analysis.definitions import PARAFAC2_TESTSET\n",
    "from pca_analysis import xr_plotly\n",
    "import plotly.io as pio\n",
    "import xarray as xr\n",
    "import darkdetect\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "xr.set_options(display_expand_data=False, display_expand_coords=False)\n",
    "\n",
    "if darkdetect.isDark():\n",
    "    pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "ds = xr.load_dataset(PARAFAC2_TESTSET)\n",
    "\n",
    "# speed up development by using a subset.\n",
    "ds = ds.sel(wavelength=slice(210, 260, 5), mins=slice(0, 30))\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "The criteria is that with the default find_peaks params, no peaks are detected before the first 0.77 seconds. This can be achieved through savgol smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca_analysis.preprocessing import smooth\n",
    "\n",
    "(\n",
    "    ds.isel(id_rank=slice(2, 6))\n",
    "    .assign(\n",
    "        smoothed=ds.raw_data.pipe(\n",
    "            smooth.savgol_smooth,\n",
    "            input_core_dims=[\n",
    "                [\"mins\"],\n",
    "            ],\n",
    "            output_core_dims=[[\"mins\"]],\n",
    "            window_length=60,\n",
    "            polyorder=2,\n",
    "        )\n",
    "    )\n",
    "    .sel(wavelength=260, mins=slice(0, 10))\n",
    "    .plotly.facet_plot_overlay(\n",
    "        grouper=\"id_rank\", var_keys=[\"raw_data\", \"smoothed\"], col_wrap=2\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Subtraction\n",
    "\n",
    "To simplify tool development, we should first subtract the baseline from each sample. Whether or not there is a baseline is questionable, however the rise and fall does roughly correspond with the change in concentration of methanol in the mobile phase, potentially introducing background absorption. Either way, the data will be easier to work with with zeroed baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca_analysis.preprocessing import bcorr\n",
    "\n",
    "\n",
    "def correct_baselines_ds(ds: xr.Dataset, core_dim, **kwargs):\n",
    "    \"\"\"\n",
    "    Correct baseline over all samples and wavelengths, adding the baseline\n",
    "    and corrected signal as variables to the dataset.\n",
    "\n",
    "    Hardcoded keys\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(ds, xr.Dataset):\n",
    "        raise TypeError\n",
    "\n",
    "    ds = ds.assign(\n",
    "        baselines=xr.apply_ufunc(\n",
    "            bcorr.apply_snip,\n",
    "            ds.raw_data,\n",
    "            kwargs=kwargs,\n",
    "            input_core_dims=[\n",
    "                [core_dim],\n",
    "            ],\n",
    "            output_core_dims=[[core_dim]],\n",
    "            # need vectorize to do the looping\n",
    "            vectorize=True,\n",
    "        )\n",
    "    )\n",
    "    ds = ds.assign(data_corr=ds.raw_data - ds.baselines)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "ds = ds.pipe(correct_baselines_ds, core_dim=\"mins\", max_half_window=30)\n",
    "display(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_fig = (\n",
    "    ds.transpose(\"id_rank\", \"wavelength\", \"mins\")\n",
    "    .isel(wavelength=0)\n",
    "    .plotly.facet_plot_overlay(\n",
    "        grouper=\"id_rank\",\n",
    "        var_keys=[\"raw_data\", \"baselines\", \"data_corr\"],\n",
    "        col_wrap=3,\n",
    "        x_key=\"mins\",\n",
    "    )\n",
    ")\n",
    "overlay_fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca-analysis-6KQS4gUX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
