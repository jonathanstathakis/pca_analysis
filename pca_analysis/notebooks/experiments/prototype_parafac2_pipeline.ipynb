{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: PARAFAC2 Pipeline Orchastrator Demonstration\n",
    "description: A prototype for a sklearn based PARAFAC2 pipeline Orchastrator with preprocessing, pipeline, postprocessing and results demonstration\n",
    "project: parafac2\n",
    "status: closed\n",
    "conclusion: \"orchastrator successfully completes the PARAFAC2 pipeline and displays results, storing them in a database in a datamart-like model\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Multistage preprocessing of data prior to modeling can quickly become difficult to manage - keeping track of the order of execution of the individual stages, modifying stages, and inspecting the data in between stages are some requirements that need to be managed. One popular method is the sklearn Pipeline object. It can be used to organise and inspect the individual stages. However, its most powerful feature is that it provides a grid search capability, allowing the user to **test** different hyperparameter combinations across the different stages. Say you wanted to see how a more aggressive baseline correction strategy would affect the binning of the signal, and thus the decomposition result. it does require a modicrum of work to set up, but the payoff is large. In this notebook we will set up a pipeline framework that will enable us to organise the stages of the pipeline and inspect the pipeline if an error is encountered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# get the test data as two tables: metadata and a samplewise stacked img table\n",
    "\n",
    "import duckdb as db\n",
    "from pca_analysis.definitions import DB_PATH_UV\n",
    "from pca_analysis.code.get_sample_data import get_ids_by_varietal\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from pca_analysis.notebooks.experiments.parafac2_pipeline.orchestrator import (\n",
    "    Orchestrator,\n",
    ")\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "con = db.connect(DB_PATH_UV)\n",
    "ids = get_ids_by_varietal(con=con, varietal=\"shiraz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Test Data\n",
    "\n",
    "We want a representative dataset small enough to enable quick iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata_filter_expr = pl.col(\"mins\").is_between(0.7, 1.39) & pl.col(\"nm\").is_between(\n",
    "    240, 270\n",
    ")\n",
    "\n",
    "orc = Orchestrator()\n",
    "orc.load_data(con=con, runids=ids, filter_expr=testdata_filter_expr)\n",
    "orc.input_data.plot_3d()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visual inspection hints at 8 peaks translating to a 8 + 1 rank, with 1 for noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = orc.run_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A demonstration of some visualisation of the decomposition results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Reconstruction in 3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.viz_recon_3d()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay Components and Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.viz_overlay_curve_components(sample=0, wavelength=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlay Input and Recon 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.viz_recon_input_overlay(sample=7, wavelength=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facet of Recon and Input 2D By Sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.viz_recon_input_overlay_facet(wavelengths=10, facet_col=\"sample\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facet by Wavelength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.viz_recon_input_overlay_facet(samples=2, facet_col=\"wavelength_point\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Is my Reconstruction Equal to the Tensorly Implementation\n",
    "\n",
    "A sanity check will be whether it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the Horizontal Sum\n",
    "\n",
    "To reconstruct the slice we sum (convolve) the components, as by definition their sum is the input X. This currently achieved by converting the individual component columns into a list and summing the list. One possible cause of the discrepency is that duckdb handles floating points slightly differently (or list sums) to numpy. To test this, we can get the component columns as a numpy array and sum them then compare to the duckdb result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results._check_computations_match_tly()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. That proves it. Any variation is caused by either polars or duckdb rather than a computation error on my part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Bare bones orchestrator with preprocessing, pipeline, postprocessing and results display is complete. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca-analysis-6KQS4gUX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
