{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: PARAFAC2 Pipeline Orchastrator Demonstration\n",
    "description: A prototype for a sklearn based PARAFAC2 pipeline Orchastrator with preprocessing, pipeline, postprocessing and results demonstration\n",
    "project: parafac2\n",
    "status: closed\n",
    "conclusion: \"orchastrator successfully completes the PARAFAC2 pipeline and displays results, storing them in a database in a datamart-like model\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Multistage preprocessing of data prior to modeling can quickly become difficult to manage - keeping track of the order of execution of the individual stages, modifying stages, and inspecting the data in between stages are some requirements that need to be managed. One popular method is the sklearn Pipeline object. It can be used to organise and inspect the individual stages. However, its most powerful feature is that it provides a grid search capability, allowing the user to **test** different hyperparameter combinations across the different stages. Say you wanted to see how a more aggressive baseline correction strategy would affect the binning of the signal, and thus the decomposition result. it does require a modicrum of work to set up, but the payoff is large. In this notebook we will set up a pipeline framework that will enable us to organise the stages of the pipeline and inspect the pipeline if an error is encountered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# get the test data as two tables: metadata and a samplewise stacked img table\n",
    "import logging\n",
    "\n",
    "import duckdb as db\n",
    "import polars as pl\n",
    "\n",
    "from pca_analysis.notebooks.experiments.parafac2_pipeline.parafac2_decomposition import (\n",
    "    get_data_run_pipeline,\n",
    ")\n",
    "from pca_analysis.notebooks.experiments.parafac2_pipeline.parafac2_viz import (\n",
    "    Parafac2Viz,\n",
    ")\n",
    "from tests.test_definitions import TEST_DB_PATH\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "with db.connect(TEST_DB_PATH) as conn:\n",
    "    ids = [x[0] for x in conn.execute(\"select distinct runid from inc_chm\").fetchall()]\n",
    "    conn.close()\n",
    "\n",
    "ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Test Data\n",
    "\n",
    "We want a representative dataset small enough to enable quick iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visual inspection hints at 8 peaks translating to a 8 + 1 rank, with 1 for noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata_filter_expr = pl.col(\"mins\").is_between(0, 2) & pl.col(\"nm\").is_between(\n",
    "    230, 270\n",
    ")\n",
    "\n",
    "df = get_data_run_pipeline(TEST_DB_PATH, ids, testdata_filter_expr)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A demonstration of some visualisation of the decomposition results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = 256\n",
    "runid = df.get_column(\"runid\")[0]\n",
    "\n",
    "pv = Parafac2Viz()\n",
    "\n",
    "pv.overlay_components_input_signal(rectified_df=df, wavelength=wavelength, runid=runid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca-analysis-6KQS4gUX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
