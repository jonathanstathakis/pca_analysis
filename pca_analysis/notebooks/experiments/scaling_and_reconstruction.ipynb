{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "cdt: 2024-09-04T14:00:00\n",
    "title: \"Meaning of Factors, Scaling and Reconstruction\"\n",
    "description: \"A demonstration of the meaning of the factors of the PARAFAC2 model from the point of view of a HPLC-MS decomposition and how to combine them to compare the pure components with the input data at scale.\"\n",
    "status: closed\n",
    "conclusion: \"Using the Zhang et al. GC-MS peak data, observation of the following features was made: The scaled elution profiles, the pure elution profiles, A as a function of K for each component and C as a function of J. A reconstruction routine was developed and visualisations the results of reconstruction. The reconstruction routine/viz should be integrated into a pipeline.\"\n",
    "project: parafac2\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "To scale the individual compound profiles for a given sample $k$ and wavelength $j$, multiply the elution profile by the corresponding concentration loading ($kth$ row of $A$) and a spectral loading ($j$th row of $C$), as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tensorly.decomposition import parafac2 as tl_parafac2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "from pca_analysis.get_sample_data import get_zhang_data\n",
    "raw_data: xr.DataArray = get_zhang_data()\n",
    "ds = xr.Dataset(data_vars={\"input_data\": raw_data})\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parafac2_args = dict(\n",
    "    return_errors=True,\n",
    "    verbose=True,\n",
    "    n_iter_max=1,\n",
    "    nn_modes=\"all\",\n",
    "    linesearch=False,\n",
    ")\n",
    "\n",
    "_decomp, err = tl_parafac2(\n",
    "    tensor_slices=raw_data.to_numpy(),\n",
    "    rank=3,\n",
    "    **parafac2_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an xarray dataset data structure for the parafac2 results..\n",
    "# got A, B, C and projections. We dont care abotu the pure B or the projections so\n",
    "# combine them into Bs.\n",
    "# for a tensor ijk A is ir, Bs is ijr and c is kr.\n",
    "# can get the coordinates from the raw data for ijk, r comes from the rank inputted.\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca_analysis import parafac2_xr as pxr\n",
    "\n",
    "parafac2_ds = pxr.decomp_as_xr(\n",
    "    input_data=raw_data,\n",
    "    rank=3,\n",
    "    decomp=_decomp,\n",
    ")\n",
    "\n",
    "ds = xr.merge([ds, parafac2_ds])\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.assign(components=pxr.comp_slices_to_xr(parafac2_ds))\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Individual Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A\n",
    "\n",
    "ds = ds.assign_coords(\n",
    "    {\n",
    "        \"rank_sample\": (\n",
    "            \"sample\",\n",
    "            [x for x in range(len(parafac2_ds.A.coords[\"sample\"]))],\n",
    "        ),\n",
    "        \"rank_component\": (\n",
    "            \"component\",\n",
    "            [str(x) for x in range(len(parafac2_ds.A.coords[\"component\"]))],\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "ds.A.plot.scatter(x=\"rank_sample\", hue=\"rank_component\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "As shown in the viz above, along all the samples (rank_sample), component 0 has the highest weighting, followed by 1 and 0. Presumably 2 is the noise component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isel(sample=slice(5, 10)).Bs.plot.line(x=\"time\", col=\"sample\", col_wrap=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "This is the elution profile of each sample prior to scaling, i.e. the pure profile. As we can see, component 2 corresponds to the background noise, while 1 and 3 represent the peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.C.plot.line(x=\"mz\")\n",
    "plt.title(\"The Spectral Profile\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The viz above is the pure spectral profile of the dataset. Note the extremely large maxima between 20 and 25 for the component corresponding to the noise, and how between 40 and 50 how an optimal S/N is reached, particularly for component 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The reconstruction is the recombination of the PARAFAC2 model into a 3 mode tensor. As I have already prepared the component slices, the simplest would be to sum them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.assign(recon=pxr.compute_reconstruction(components=ds.components))\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while we earlier treated the components as a variable with a component dim,\n",
    "# we now want to treat it component dim as a subset of a dim 'signal' of which\n",
    "# input_data and recon would fall into as well. This is actually more correct\n",
    "# as their units are the same - AU (?)\n",
    "# doing this from the xarray dataset is not straight forward.A\n",
    "\n",
    "# first make the \"component\" dim categorical by casting it to str and naming it \"signal\" then concat the input data and components vars, dropping differing coords.\n",
    "\n",
    "ds_ = ds.rename({\"component\": \"signal\"})\n",
    "components_ = (\n",
    "    ds_.components.assign_coords(component=ds_.components.coords[\"signal\"].astype(str))\n",
    "    .drop_vars(\"rank_component\")\n",
    "    .drop_vars(\"component\")\n",
    ")\n",
    "input_data_ = ds_.input_data.expand_dims(dim={\"signal\": [\"input_data\"]}).transpose(\n",
    "    \"sample\", \"signal\", \"time\", \"mz\"\n",
    ")\n",
    "\n",
    "# secondly select the subset to plot and viz.\n",
    "xr.concat(\n",
    "    dim=\"signal\",\n",
    "    objs=[\n",
    "        components_,\n",
    "        input_data_,\n",
    "    ],\n",
    ").isel(mz=35, sample=slice(5, 10)).plot.line(\n",
    "    x=\"time\", col=\"sample\", hue=\"signal\", col_wrap=3\n",
    ")\n",
    "\n",
    "plt.title(\"Input Data and Components per Sample\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "As we can see in the above viz, the decomposition looks sound, and fruthermore the visualisation is very informative, containing information about the pure analytes and noise compared to the convoluted signal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Using the Zhang et al. GC-MS peak data, observation of the following features was made: The scaled elution profiles, the pure elution profiles, A as a function of K for each component and C as a function of J. A reconstruction routine was developed and visualisations the results of reconstruction. The reconstruction routine/viz should be integrated into a pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca-analysis-6KQS4gUX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
