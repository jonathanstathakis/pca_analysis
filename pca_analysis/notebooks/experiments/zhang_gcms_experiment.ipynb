{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Rank Estimation of GC-MS Data\n",
    "description: A test of rank estimation methods on the Zhang et al. GC-MS data to recreate their results\n",
    "project: parafac2\n",
    "conclusion: was able to reproduce their results for the specified peaks, but the inclusion of more peaks resulted in failure\n",
    "status: closed\n",
    "cdt: 2024-08-30T00:00:00\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Rank Estimation\n",
    "\n",
    "An experiment of rank estimation on a toy dataset and the raw UV-Vis dataset. It will follow the method described in @zhang_flexibleimplementationtrilinearity_2022. First we will recreate the GC-MS dataset as described and build an implementation to preprocess, unfold, decompose and display the estimated singular values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Toy Dataset\n",
    "\n",
    "The GC-MS data was downloaded from [here](https://ucphchemometrics.com/2023/06/01/wine-samples-analyzed-by-gc-ms-and-ft-ir-instruments/) and originally prepared by @skov_multiblockvariancepartitioning_2008. It is stored in MATLAB 7.3 format and required the use of [mat73](https://gitlab.com/obob/pymatreader/) library. Within the library is GC-MS, FT-I and physicochemical univariate measurements. The GC-MS data consists of 44 samples x 2700 elution time-points and 200 mass channels.\n",
    "\n",
    "The authors narrowed the scope to range from 16.52 to 16.76 mins (corresponding to a range of 25 units) containing two compounds (peaks). They identified three significant components (chemical rank) attributing two to the compounds stated and one to the background. We expect to find the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
"%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import numpy as np\n",
    "from pymatreader import read_mat\n",
    "import xarray as xr\n",
    "from tensorly import unfold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import signal\n",
    "from copy import deepcopy\n",
    "\n",
    "from pca_analysis.definitions import DATA_DIR, ROOT\n",
    "\n",
    "xr.set_options(display_expand_data=False)\n",
    "\n",
    "mat_path = DATA_DIR / \"Wine_v7.mat\"\n",
    "nc_path = DATA_DIR / \"Wine_v7.nc\"\n",
    "\n",
    "if nc_path.exists():\n",
    "    full_data = xr.open_dataarray(nc_path)\n",
    "\n",
    "else:\n",
    "    mat_data = read_mat(mat_path)\n",
    "\n",
    "    key_it = [\n",
    "        \"Label_Wine_samples\",\n",
    "        \"Label_Elution_time\",\n",
    "        \"Label_Mass_channels\",\n",
    "    ]\n",
    "\n",
    "    raw_data = xr.DataArray(\n",
    "        mat_data[\"Data_GC\"],\n",
    "        dims=[\"sample\", \"time\", \"mz\"],\n",
    "        coords=[mat_data[k] for k in key_it],\n",
    "    )\n",
    "\n",
    "    raw_data.to_netcdf(nc_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We will organise the data in a labelled xarray for ease of handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "To perform the SVD the data needs to be scaled and centered. It doesn't appear as though @zhang_flexibleimplementationtrilinearity_2022 did this, at least they didnt report it. So I will begin PCA without. If the results are poor, I will integrate this preprocessing stage. I think I would mean center columns (observations) and scale rows (samples). TODO: find resources for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "\n",
    "I will use [tensorly](https://tensorly.org/stable/user_guide/tensor_basics.html#unfolding) to unfold the numpy array. Leaving the xarray for now as it has a potentially different API. Which is fine, but now the modes are unlabelled. Which is still fine, just need to reapply them. Easiest to extract then implement manually. Its probably easist just to find the indexes manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sliced_data = full_data.sel(time=slice(16.52, 16.76))  # interval taken from article\n",
    "display(sliced_data)\n",
    "sliced_data[0].plot.line(x=\"time\", add_legend=False);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Which looks correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Unfolding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3bb57f",
   "metadata": {},
   "source": [
    "Unfolding along sample mode such that the matrix is stacked sample-wise with rows as sample, time and columns as wavelengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c68030",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_aug = sliced_data.stack(sample_aug=(\"sample\", \"time\")).transpose(..., \"mz\")\n",
    "sample_aug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "As we are skipping scaling and centering for now, we will proceed with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "sample_aug.pipe(pca.fit_transform);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "We will crudely define the inflection point as being the location where the finite difference becomes less than 2% of the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca_analysis.notebooks.experiments.zhang_pca_scree_plot import pca_scree_plot\n",
    "\n",
    "pca_scree_plot(explained_variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "user_expressions": [
     {
      "expression": "sig_component_idxs[0][-1]+1",
      "result": {
       "ename": "NameError",
       "evalue": "name 'sig_component_idxs' is not defined",
       "status": "error",
       "traceback": [
        "\u001b[0;31mNameError\u001b[0m\u001b[0;31m:\u001b[0m name 'sig_component_idxs' is not defined\n"
       ]
      }
     }
    ]
   },
   "source": [
    "According to the rule of <2% change, the number of significant components is deemed to be {eval}`sig_component_idxs[0][-1]+1`, which is in agreement with the authors, and no preprocessing was necessary.\n",
    "\n",
    "This example will remain as a test case, we will now test it on the entire toy dataset, then my dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Full Dataset\n",
    "\n",
    "Do the same thing but for the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Visual Estimation of Number of Peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "What are the number of components expected? It should be close to the number of peaks in the maximum mass channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average mz over time and samples\n",
    "\n",
    "mean_max_mz = raw_data.mean(\"time\").mean(\"sample\").idxmax().item()\n",
    "mean_max_mz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "user_expressions": [
     {
      "expression": "mean_max_mz",
      "result": {
       "data": {
        "text/plain": "44.0"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "The mz with the maximum abs is: {eval}`mean_max_mz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "And which sample has the highest average for that channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sample = raw_data.sel({\"mz\": 39}).mean(\"time\").idxmax().item()\n",
    "max_sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "user_expressions": [
     {
      "expression": "max_sample",
      "result": {
       "data": {
        "text/html": "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n<defs>\n<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n</symbol>\n<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n</symbol>\n</defs>\n</svg>\n<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n *\n */\n\n:root {\n  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n  --xr-background-color: var(--jp-layout-color0, white);\n  --xr-background-color-row-even: var(--jp-layout-color1, white);\n  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n}\n\nhtml[theme=dark],\nhtml[data-theme=dark],\nbody[data-theme=dark],\nbody.vscode-dark {\n  --xr-font-color0: rgba(255, 255, 255, 1);\n  --xr-font-color2: rgba(255, 255, 255, 0.54);\n  --xr-font-color3: rgba(255, 255, 255, 0.38);\n  --xr-border-color: #1F1F1F;\n  --xr-disabled-color: #515151;\n  --xr-background-color: #111111;\n  --xr-background-color-row-even: #111111;\n  --xr-background-color-row-odd: #313131;\n}\n\n.xr-wrap {\n  display: block !important;\n  min-width: 300px;\n  max-width: 700px;\n}\n\n.xr-text-repr-fallback {\n  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n  display: none;\n}\n\n.xr-header {\n  padding-top: 6px;\n  padding-bottom: 6px;\n  margin-bottom: 4px;\n  border-bottom: solid 1px var(--xr-border-color);\n}\n\n.xr-header > div,\n.xr-header > ul {\n  display: inline;\n  margin-top: 0;\n  margin-bottom: 0;\n}\n\n.xr-obj-type,\n.xr-array-name {\n  margin-left: 2px;\n  margin-right: 10px;\n}\n\n.xr-obj-type {\n  color: var(--xr-font-color2);\n}\n\n.xr-sections {\n  padding-left: 0 !important;\n  display: grid;\n  grid-template-columns: 150px auto auto 1fr 20px 20px;\n}\n\n.xr-section-item {\n  display: contents;\n}\n\n.xr-section-item input {\n  display: none;\n}\n\n.xr-section-item input + label {\n  color: var(--xr-disabled-color);\n}\n\n.xr-section-item input:enabled + label {\n  cursor: pointer;\n  color: var(--xr-font-color2);\n}\n\n.xr-section-item input:enabled + label:hover {\n  color: var(--xr-font-color0);\n}\n\n.xr-section-summary {\n  grid-column: 1;\n  color: var(--xr-font-color2);\n  font-weight: 500;\n}\n\n.xr-section-summary > span {\n  display: inline-block;\n  padding-left: 0.5em;\n}\n\n.xr-section-summary-in:disabled + label {\n  color: var(--xr-font-color2);\n}\n\n.xr-section-summary-in + label:before {\n  display: inline-block;\n  content: '►';\n  font-size: 11px;\n  width: 15px;\n  text-align: center;\n}\n\n.xr-section-summary-in:disabled + label:before {\n  color: var(--xr-disabled-color);\n}\n\n.xr-section-summary-in:checked + label:before {\n  content: '▼';\n}\n\n.xr-section-summary-in:checked + label > span {\n  display: none;\n}\n\n.xr-section-summary,\n.xr-section-inline-details {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n.xr-section-inline-details {\n  grid-column: 2 / -1;\n}\n\n.xr-section-details {\n  display: none;\n  grid-column: 1 / -1;\n  margin-bottom: 5px;\n}\n\n.xr-section-summary-in:checked ~ .xr-section-details {\n  display: contents;\n}\n\n.xr-array-wrap {\n  grid-column: 1 / -1;\n  display: grid;\n  grid-template-columns: 20px auto;\n}\n\n.xr-array-wrap > label {\n  grid-column: 1;\n  vertical-align: top;\n}\n\n.xr-preview {\n  color: var(--xr-font-color3);\n}\n\n.xr-array-preview,\n.xr-array-data {\n  padding: 0 5px !important;\n  grid-column: 2;\n}\n\n.xr-array-data,\n.xr-array-in:checked ~ .xr-array-preview {\n  display: none;\n}\n\n.xr-array-in:checked ~ .xr-array-data,\n.xr-array-preview {\n  display: inline-block;\n}\n\n.xr-dim-list {\n  display: inline-block !important;\n  list-style: none;\n  padding: 0 !important;\n  margin: 0;\n}\n\n.xr-dim-list li {\n  display: inline-block;\n  padding: 0;\n  margin: 0;\n}\n\n.xr-dim-list:before {\n  content: '(';\n}\n\n.xr-dim-list:after {\n  content: ')';\n}\n\n.xr-dim-list li:not(:last-child):after {\n  content: ',';\n  padding-right: 5px;\n}\n\n.xr-has-index {\n  font-weight: bold;\n}\n\n.xr-var-list,\n.xr-var-item {\n  display: contents;\n}\n\n.xr-var-item > div,\n.xr-var-item label,\n.xr-var-item > .xr-var-name span {\n  background-color: var(--xr-background-color-row-even);\n  margin-bottom: 0;\n}\n\n.xr-var-item > .xr-var-name:hover span {\n  padding-right: 5px;\n}\n\n.xr-var-list > li:nth-child(odd) > div,\n.xr-var-list > li:nth-child(odd) > label,\n.xr-var-list > li:nth-child(odd) > .xr-var-name span {\n  background-color: var(--xr-background-color-row-odd);\n}\n\n.xr-var-name {\n  grid-column: 1;\n}\n\n.xr-var-dims {\n  grid-column: 2;\n}\n\n.xr-var-dtype {\n  grid-column: 3;\n  text-align: right;\n  color: var(--xr-font-color2);\n}\n\n.xr-var-preview {\n  grid-column: 4;\n}\n\n.xr-index-preview {\n  grid-column: 2 / 5;\n  color: var(--xr-font-color2);\n}\n\n.xr-var-name,\n.xr-var-dims,\n.xr-var-dtype,\n.xr-preview,\n.xr-attrs dt {\n  white-space: nowrap;\n  overflow: hidden;\n  text-overflow: ellipsis;\n  padding-right: 10px;\n}\n\n.xr-var-name:hover,\n.xr-var-dims:hover,\n.xr-var-dtype:hover,\n.xr-attrs dt:hover {\n  overflow: visible;\n  width: auto;\n  z-index: 1;\n}\n\n.xr-var-attrs,\n.xr-var-data,\n.xr-index-data {\n  display: none;\n  background-color: var(--xr-background-color) !important;\n  padding-bottom: 5px !important;\n}\n\n.xr-var-attrs-in:checked ~ .xr-var-attrs,\n.xr-var-data-in:checked ~ .xr-var-data,\n.xr-index-data-in:checked ~ .xr-index-data {\n  display: block;\n}\n\n.xr-var-data > table {\n  float: right;\n}\n\n.xr-var-name span,\n.xr-var-data,\n.xr-index-name div,\n.xr-index-data,\n.xr-attrs {\n  padding-left: 25px !important;\n}\n\n.xr-attrs,\n.xr-var-attrs,\n.xr-var-data,\n.xr-index-data {\n  grid-column: 1 / -1;\n}\n\ndl.xr-attrs {\n  padding: 0;\n  margin: 0;\n  display: grid;\n  grid-template-columns: 125px auto;\n}\n\n.xr-attrs dt,\n.xr-attrs dd {\n  padding: 0;\n  margin: 0;\n  float: left;\n  padding-right: 10px;\n  width: auto;\n}\n\n.xr-attrs dt {\n  font-weight: normal;\n  grid-column: 1;\n}\n\n.xr-attrs dt:hover span {\n  display: inline-block;\n  background: var(--xr-background-color);\n  padding-right: 10px;\n}\n\n.xr-attrs dd {\n  grid-column: 2;\n  white-space: pre-wrap;\n  word-break: break-all;\n}\n\n.xr-icon-database,\n.xr-icon-file-text2,\n.xr-no-icon {\n  display: inline-block;\n  vertical-align: middle;\n  width: 1em;\n  height: 1.5em !important;\n  stroke-width: 0;\n  stroke: currentColor;\n  fill: currentColor;\n}\n</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray (time: 2700)&gt; Size: 22kB\narray([0.0002915 , 0.00042047, 0.00032257, ..., 0.00043929, 0.00042385,\n       0.00046607])\nCoordinates:\n    sample   &lt;U8 32B &#x27;AUS-KIL1&#x27;\n  * time     (time) float64 22kB 0.006245 0.01874 0.03123 ... 33.69 33.71 33.72\n    m/z      float64 8B 44.0</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 2700</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-332be916-258b-46c7-9d20-a31121e74889' class='xr-array-in' type='checkbox' checked><label for='section-332be916-258b-46c7-9d20-a31121e74889' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.0002915 0.0004205 0.0003226 ... 0.0004393 0.0004238 0.0004661</span></div><div class='xr-array-data'><pre>array([0.0002915 , 0.00042047, 0.00032257, ..., 0.00043929, 0.00042385,\n       0.00046607])</pre></div></div></li><li class='xr-section-item'><input id='section-d57db00c-7322-4df6-b25c-99fdfd8015b0' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d57db00c-7322-4df6-b25c-99fdfd8015b0' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>sample</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>&lt;U8</div><div class='xr-var-preview xr-preview'>&#x27;AUS-KIL1&#x27;</div><input id='attrs-6d856774-b5c0-41eb-9a7c-1a1a2c29299c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6d856774-b5c0-41eb-9a7c-1a1a2c29299c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2bafb34d-fd78-47b7-aa4d-3fe9da4fe5f1' class='xr-var-data-in' type='checkbox'><label for='data-2bafb34d-fd78-47b7-aa4d-3fe9da4fe5f1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array(&#x27;AUS-KIL1&#x27;, dtype=&#x27;&lt;U8&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.006245 0.01874 ... 33.71 33.72</div><input id='attrs-6df14cd2-eaa7-4931-8115-59152d5cdc80' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6df14cd2-eaa7-4931-8115-59152d5cdc80' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-58513c23-78a7-4dd5-aef9-adc8b9700f15' class='xr-var-data-in' type='checkbox'><label for='data-58513c23-78a7-4dd5-aef9-adc8b9700f15' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([6.245292e-03, 1.873588e-02, 3.122646e-02, ..., 3.369335e+01,\n       3.370584e+01, 3.371833e+01])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>m/z</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>44.0</div><input id='attrs-b814658e-f5ca-4d4e-9bf2-86c4f270b37b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b814658e-f5ca-4d4e-9bf2-86c4f270b37b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fc34111c-91e3-43ed-abc0-2122b1390b89' class='xr-var-data-in' type='checkbox'><label for='data-fc34111c-91e3-43ed-abc0-2122b1390b89' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array(44.)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-63936c31-71cd-4720-8c61-f0c3aeea36b6' class='xr-section-summary-in' type='checkbox'  ><label for='section-63936c31-71cd-4720-8c61-f0c3aeea36b6' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-98265393-f0f7-409d-bee4-8bbf0892bb41' class='xr-index-data-in' type='checkbox'/><label for='index-98265393-f0f7-409d-bee4-8bbf0892bb41' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([0.006245292451258124, 0.018735877353774372,  0.03122646225629062,\n       0.043717047158806865,  0.05620763206132312,  0.06869821696383936,\n        0.08118880186635562,  0.09367938676887186,  0.10616997167138811,\n        0.11866055657390435,\n       ...\n         33.605918680219965,    33.61840926512248,   33.630899850024996,\n          33.64339043492751,   33.655881019830026,    33.66837160473255,\n         33.680862189635064,    33.69335277453758,   33.705843359440095,\n          33.71833394434261],\n      dtype=&#x27;float64&#x27;, name=&#x27;time&#x27;, length=2700))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-e01d1b84-5525-493e-8d25-64efb0a08a25' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-e01d1b84-5525-493e-8d25-64efb0a08a25' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>",
        "text/plain": "<xarray.DataArray (time: 2700)> Size: 22kB\narray([0.0002915 , 0.00042047, 0.00032257, ..., 0.00043929, 0.00042385,\n       0.00046607])\nCoordinates:\n    sample   <U8 32B 'AUS-KIL1'\n  * time     (time) float64 22kB 0.006245 0.01874 0.03123 ... 33.69 33.71 33.72\n    m/z      float64 8B 44.0"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "which is {eval}`max_sample`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "A visual observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sample = raw_data.sel({\"mz\": mean_max_mz, \"sample\": max_sample})\n",
    "\n",
    "max_sample.plot.line()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sample.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindPeaks:\n",
    "    def find_peaks(self, sample, height_ratio=0.001):\n",
    "        self.height = (sample.max() * height_ratio).item()\n",
    "        self.peaks, self.properties = signal.find_peaks(sample, height=self.height)\n",
    "\n",
    "        self.peaks_x = sample[\"time\"][self.peaks].to_numpy()\n",
    "        self.peaks_y = sample[self.peaks].to_numpy()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def plot_peaks(self, sample):\n",
    "        sample.plot.line()\n",
    "        plt.scatter(self.peaks_x, self.peaks_y)\n",
    "        plt.xlim(0, 25)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "fp = FindPeaks()\n",
    "fp.find_peaks(sample=max_sample)\n",
    "fp.plot_peaks(sample=max_sample)\n",
    "peaks_x, peaks_y = fp.peaks_x, fp.peaks_y\n",
    "peaks_x, peaks_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "user_expressions": [
     {
      "expression": "len(peaks)",
      "result": {
       "data": {
        "text/plain": "22"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "Visually it appears that all peaks are accounted for, thus the number of peaks is around {eval}`len(peaks)`. Thus we should expect around 22 significant components through PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Unfold Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "caug = raw_data.stack({\"aug\": (\"sample\", \"time\")}).transpose(..., \"mz\")\n",
    "caug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "\n",
    "class MyPCA:\n",
    "    def run_pca(self, data):\n",
    "        obj = deepcopy(self)\n",
    "        obj.pca = decomposition.PCA()\n",
    "\n",
    "        obj.pca.fit_transform(data)\n",
    "\n",
    "        return obj\n",
    "\n",
    "    def scree_plot(self):\n",
    "        if not hasattr(self, \"pca\"):\n",
    "            raise RuntimeError(\"call `run_pca` first\")\n",
    "\n",
    "        xp_var = self.pca.explained_variance_[:10]\n",
    "        x = range(1, len(xp_var) + 1)\n",
    "        plt.bar(x, xp_var)\n",
    "        plt.xlabel(\"components\")\n",
    "        plt.ylabel(\"explained variance\")\n",
    "        plt.title(\"explained variance vs. explained components\")\n",
    "        plt.plot(x, np.cumsum(xp_var), \"r\")\n",
    "\n",
    "\n",
    "pca = MyPCA()\n",
    "pca = pca.run_pca(caug)\n",
    "pca.scree_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "But as we can see, the profile is coincidentally similar to the 2 peak slice with the vast majority of the variance explained by the first three compoonents, infact by the first two. We can presume that this is because of the dominance of the maxima peak. If we remove it from the set.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Without Maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut it the signal half way between the first two peaks\n",
    "\n",
    "# cut the maxima off while retaining a decent amount of baseline\n",
    "\n",
    "maxima_idx = peaks_y.argmax()\n",
    "next_peak_idx = maxima_idx + 1\n",
    "cut_time_start = peaks_x[maxima_idx] + (peaks_x[next_peak_idx] - peaks_x[maxima_idx])\n",
    "\n",
    "mean_distance = int(np.ceil(np.diff(peaks_x).mean()))\n",
    "last_peak = peaks_x[-1]\n",
    "cut_time_end = last_peak + mean_distance\n",
    "\n",
    "# chop the empty component of the signal off - empty is defined as a distance from the last peak equal to the average gap between peaks\n",
    "\n",
    "# average gap between peaks\n",
    "\n",
    "shortened = raw_data.where(\n",
    "    (raw_data.time >= cut_time_start) & (raw_data.time <= cut_time_end)\n",
    ").dropna(\"time\")\n",
    "shortened.sel(mz=44).plot(col=\"sample\", col_wrap=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Looks good. Whats the PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_shortened = shortened.stack({\"aug\": (\"sample\", \"time\")}).transpose(..., \"mz\")\n",
    "\n",
    "pca_shortened = pca.run_pca(data=stacked_shortened)\n",
    "pca_shortened.scree_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "um. Kind of better? At least the drop off isnt so harsh, but evidently the PCA is still being dominated by only a few latent variables. Its time to implement scaling and centering, then if that doesnt work, binning *shudder*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Want to mean center the columns, scale the sample rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "scaler = StandardScaler()\n",
    "normed = normalizer.fit_transform(stacked_shortened)\n",
    "scaled_normed = scaler.fit_transform(normed)\n",
    "scaled_normed.shape\n",
    "normed[0:10, 0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is mean centered if the following equals zero.\n",
    "\n",
    "np.mean(np.abs(np.round(np.mean(scaled_normed, axis=0), 9)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_sn = pca.run_pca(scaled_normed)\n",
    "pca.scree_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "Same. Fairly evident that binning is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## CORCONDIA\n",
    "\n",
    "As the PCA approaches are failing to produce the expected results without extensive manual handling, we will move on to CORCONDIA, a method of approximating the number of components of PARAFAC and PARAFAC-like models (i.e. PARAFAC2) through observation of a Tucker3 core [@bro_newefficientmethod_2003]. It will iterate through components, starting at 1, until a limit (?) and we are looking for a steep dropoff as the indication of the optimal number of components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corcondia import corcondia_3d\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "raw_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "corcondia_3d(X=raw_data.transpose(\"sample\", \"time\", \"mz\").to_numpy(), k=22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "corcondia hasnt worked. The vibe of things is that none of these tools work for high numbers of peaks. Binning is required.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## PARAFAC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorly.decomposition import parafac2\n",
    "\n",
    "best_err = np.inf\n",
    "decomposition = None\n",
    "\n",
    "true_rank = 22\n",
    "\n",
    "for run in range(1):\n",
    "    print(f\"Training model {run}...\")\n",
    "    trial_decomposition, trial_errs = parafac2(\n",
    "        raw_data[0:5, :, :].to_numpy(),\n",
    "        true_rank,\n",
    "        return_errors=True,\n",
    "        tol=1e-8,\n",
    "        n_iter_max=500,\n",
    "        random_state=run,\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(f\"Number of iterations: {len(trial_errs)}\")\n",
    "    print(f\"Final error: {trial_errs[-1]}\")\n",
    "    if best_err > trial_errs[-1]:\n",
    "        best_err = trial_errs[-1]\n",
    "        err = trial_errs\n",
    "        decomposition = trial_decomposition\n",
    "    print(\"-------------------------------\")\n",
    "print(f\"Best model error: {best_err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
